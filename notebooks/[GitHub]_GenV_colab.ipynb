{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJCfDyyKRv3P"
      },
      "source": [
        "Copyright 2025 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7AMunkq7Mdb"
      },
      "source": [
        "# Gen V Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbt69GlmAHU4"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MyZdmMvlAOfe"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "!pip install --upgrade --quiet google-genai\n",
        "!pip install --quiet mediapy\n",
        "!pip install --quiet moviepy==2.1.2\n",
        "!pip install --quiet 'git+https://github.com/google-marketing-solutions/gen-v.git@main#egg=gtech-gen-v&subdirectory=backend'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScOkw_T7Adfl"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import base64\n",
        "import ipywidgets as widgets\n",
        "import mediapy as media\n",
        "import moviepy as mp\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from datetime import date\n",
        "from IPython.display import clear_output\n",
        "from gen_v import config\n",
        "from gen_v import models\n",
        "from gen_v import storage as gcs\n",
        "from gen_v import utils\n",
        "from gen_v import video\n",
        "from google import genai\n",
        "\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageDraw, ImageFont"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC61ooM4Ee8T"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate User\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6HWaRHf9QZ-"
      },
      "source": [
        "\n",
        "## Parameters Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjLklHMq7hZC"
      },
      "outputs": [],
      "source": [
        "# @title GCP Parameters\n",
        "\n",
        "GCP_PROJECT_ID = 'your-project-id'  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "GEMINI_PROJECT_ID = GCP_PROJECT_ID\n",
        "IMAGEN_PROJECT_ID = GCP_PROJECT_ID\n",
        "VEO_PROJECT_ID = GCP_PROJECT_ID\n",
        "\n",
        "GCP_BUCKET_NAME = 'your-bucket-name' # @param {type: \"string\", placeholder: \"bucket-name-without-path\"}\n",
        "INPUT_IMAGE_BUCKET_NAME = GCP_BUCKET_NAME\n",
        "FOLDER_NAME = 'your-folder-name' #@param {type: \"string\"}\n",
        "INPUT_AUDIO_BUCKET_PATH = f'{FOLDER_NAME}/audio/'\n",
        "\n",
        "OUTPUT_IMAGES_BUCKET_NAME = GCP_BUCKET_NAME\n",
        "OUTPUT_IMAGES_BUCKET_PATH = f'{FOLDER_NAME}/output-images/'\n",
        "OUTPUT_VIDEOS_BUCKET_NAME = GCP_BUCKET_NAME\n",
        "OUTPUT_VIDEOS_BUCKET_PATH = f'{FOLDER_NAME}/output-videos/'\n",
        "OUTPUT_VIDEOS_URI = f\"gs://{OUTPUT_VIDEOS_BUCKET_NAME}/{OUTPUT_VIDEOS_BUCKET_PATH}\"\n",
        "\n",
        "\n",
        "TMP_STRING = '/content'\n",
        "\n",
        "# Set current date variables, used in GCS URI paths\n",
        "CURRENT_YEAR, CURRENT_WEEK, _ = date.today().isocalendar()\n",
        "WEEK_AND_YEAR = f\"week{CURRENT_WEEK}-{CURRENT_YEAR}\"\n",
        "\n",
        "IMAGE_OVERLAYS_PATH = f\"{OUTPUT_VIDEOS_BUCKET_NAME}/{OUTPUT_VIDEOS_BUCKET_PATH}image_overlays/{WEEK_AND_YEAR}\"\n",
        "FINAL_OVERLAYS_PATH = f\"{OUTPUT_VIDEOS_BUCKET_NAME}/{OUTPUT_VIDEOS_BUCKET_PATH}final_overlays/{WEEK_AND_YEAR}\"\n",
        "OUTPUT_URI_PATH = f\"{OUTPUT_IMAGES_BUCKET_NAME}/{OUTPUT_IMAGES_BUCKET_PATH}{WEEK_AND_YEAR}\"\n",
        "\n",
        "VEO_OVERLAYS_FOLDER = f'{OUTPUT_VIDEOS_BUCKET_NAME}/{OUTPUT_VIDEOS_BUCKET_PATH}final_overlays/'\n",
        "VEO_CLIPS_URI = f\"{VEO_OVERLAYS_FOLDER}{WEEK_AND_YEAR}/\"\n",
        "\n",
        "STITCHING_OUTPUT_URI = f'{OUTPUT_VIDEOS_URI}concatenated/{WEEK_AND_YEAR}/'\n",
        "\n",
        "folder_names = ['audio', 'fonts', 'input-images', 'input-overlays', 'input-videos', 'logos']\n",
        "\n",
        "gcs.create_gcs_folders_in_subfolder(GCP_BUCKET_NAME, FOLDER_NAME, folder_names)\n",
        "gcs.create_gcs_folders_in_subfolder(GCP_BUCKET_NAME, f'{FOLDER_NAME}/input-images',[WEEK_AND_YEAR])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfksQatIAg5q"
      },
      "outputs": [],
      "source": [
        "#@title GenAI models parameters\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "video_model = \"veo-2.0-generate-001\"\n",
        "gemini_model = \"gemini-2.0-flash\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57MS2BdC77bh"
      },
      "outputs": [],
      "source": [
        "# @title Image Editing Parameters\n",
        "\n",
        "RESIZED_IMAGE_WIDTH = 1280 # @param\n",
        "RESIZED_IMAGE_HEIGHT = 720 # @param\n",
        "# @markdown ----\n",
        "\n",
        "# @markdown Enable this to show images during processing\n",
        "COLOR_BACKGROUND_REPLACEMENT = True # @param {type: 'boolean'}\n",
        "\n",
        "BACKGROUND_RED = 255 # @param\n",
        "BACKGROUND_GREEN = 224 # @param\n",
        "BACKGROUND_BLUE = 77 # @param\n",
        "BACKGROUND_TRANSPARENCY = 255\n",
        "\n",
        "ORIGINAL_BACKGROUND_COLOR = models.RGBColor.from_tuple((255,255,255))\n",
        "BACKGROUND_COLOR = models.RGBColor.from_tuple((\n",
        "    BACKGROUND_RED,\n",
        "    BACKGROUND_GREEN,\n",
        "    BACKGROUND_BLUE\n",
        "))\n",
        "\n",
        "\n",
        "# Use this to convert HEX color to RGB\n",
        "# hex_color = \"#fcdc4c\"\n",
        "# rgb_color = utils.hex_to_rgb(hex_color)\n",
        "# print(rgb_color)  # Output: (R, G, B)\n",
        "\n",
        "# @markdown ----\n",
        "\n",
        "# @markdown Enable this to show images during processing\n",
        "ENABLE_SHOW_IMAGES_INLINE = False # @param {type: \"boolean\"}\n",
        "SHOW_IMAGE_HEIGHT = 500 # @param [250,500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0423lHbe9BzW"
      },
      "outputs": [],
      "source": [
        "# @title Video Generation Parameters\n",
        "\n",
        "# @markdown Set VEO parameters\n",
        "DURATION = 5  # @param {type:\"slider\", min:5, max:8, step:1}\n",
        "SAMPLE_COUNT = 2  # @param {type:\"slider\", min:1, max:4, step:1}\n",
        "NEGATIVE_PROMPT = \"copyrighted content\"  # @param {type: 'string'}\n",
        "PROMPT_ENHANCE = True  # @param {type: 'boolean'}\n",
        "PERSON_GENERATION = \"allow_adult\"  #@param [\"allow_adult\", \"dont_allow\"]\n",
        "\n",
        "# @markdown ----\n",
        "\n",
        "# @markdown Decide which prompt to use\n",
        "PROMPT_TYPE = \"CUSTOM\" # @param [\"CUSTOM\", \"GEMINI\"]\n",
        "# @markdown Your Veo prompt aka CUSTOM\n",
        "CUSTOM_VIDEO_PROMPT = \"Animate this image in a way that is most appropriate for the content in the image\" # @param [\"Animate this image in a way that is most appropriate for the content in the image\"] {\"allow-input\":true}\n",
        "# @markdown Let Gemini generate a video prompt aka GEMINI\n",
        "GENERATE_VIDEO_PROMPT = \"Analyse the image and write a prompt for a generative video AI to animate the video in the most appropriate way for the content to be displayed in an online ad.  Consider the function of the main object in the image when deciding how to animate it.  If there is a background, focus on animating the primary object only. Output the prompt only. Don't show any of the anlaysis or headings in your response, only provide the prompt you created.\" # @param [\"Analyse the image and write a prompt for a generative video AI to animate the video in the most appropriate way for the content to be displayed in an online ad.  Consider the function of the main object in the image when deciding how to animate it.  If there is a background, focus on animating the primary object only. Output the prompt only. Don't show any of the anlaysis or headings in your response, only provide the prompt you created.\"] {\"allow-input\":true}\n",
        "\n",
        "# @markdown ----\n",
        "\n",
        "VIDEO_ORIENTATION = \"LANDSCAPE\" # @param [\"LANDSCAPE\", \"PORTRAIT\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caeI68sF9IkM"
      },
      "outputs": [],
      "source": [
        "# @title Overlay Parameters\n",
        "\n",
        "LOGO_FILE_NAME = \"logo.png\" #@param {type: 'string'}\n",
        "LOGO_URI = f'gs://{GCP_BUCKET_NAME}/{FOLDER_NAME}/logos/{LOGO_FILE_NAME}'\n",
        "STICKER_FILE_NAME = \"sticker.png\" #@param {type: 'string'}\n",
        "STICKER_URI = f'gs://{GCP_BUCKET_NAME}/{FOLDER_NAME}/input-overlays/{STICKER_FILE_NAME}'\n",
        "FONT_FILE_NAME = \"font.ttf\" #@param {type: 'string'}\n",
        "FONT_URI = f'gs://{GCP_BUCKET_NAME}/{FOLDER_NAME}/fonts/{FONT_FILE_NAME}'\n",
        "\n",
        "OVERLAY_WIDTH = RESIZED_IMAGE_WIDTH\n",
        "OVERLAY_HEIGTH = RESIZED_IMAGE_HEIGHT\n",
        "\n",
        "LOGO_POSITION = (50, 520) #@param\n",
        "LOGO_DESIRED_HEIGHT = 150 #@param Set as 0 to avoid auto-scaling\n",
        "LOGO_START = 0 #@param\n",
        "LOGO_DURATION = 5 #@param\n",
        "\n",
        "\n",
        "STICKER_POSITION = (50, 50) #@param\n",
        "STICKER_START = 0 #@param\n",
        "STICKER_DURATION = 5 #@param\n",
        "STICKER_DESIRED_HEIGHT = 100 #@param\n",
        "\n",
        "TEXT_FONT_SIZE = 30 #@param\n",
        "TEXT_START = 0 #@param\n",
        "TEXT_DURATION = 5 #@param\n",
        "TEXT_COLOR = 'blue'   #@param\n",
        "TEXT_POSITION = (850, 50)  #@param\n",
        "\n",
        "GCS_IMAGES_TEST: list[models.ImageInput] = [\n",
        "    models.ImageInput(\n",
        "        path=LOGO_URI,\n",
        "        start=LOGO_START,\n",
        "        position=LOGO_POSITION,\n",
        "        duration=LOGO_DURATION,\n",
        "        height=LOGO_DESIRED_HEIGHT\n",
        "      ),\n",
        "    models.ImageInput(\n",
        "        path=STICKER_URI,\n",
        "        start=STICKER_START,\n",
        "        position=STICKER_POSITION,\n",
        "        duration=STICKER_DURATION,\n",
        "        height=STICKER_DESIRED_HEIGHT\n",
        "      )\n",
        "    ]\n",
        "\n",
        "TEXT_TEST = models.TextInput(\n",
        "    text=\"text_to_display\",\n",
        "    font=FONT_URI,\n",
        "    font_size=TEXT_FONT_SIZE,\n",
        "    start_time=TEXT_START,\n",
        "    duration=TEXT_DURATION,\n",
        "    color=TEXT_COLOR,\n",
        "    position=TEXT_POSITION\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcDkmy2J_GIO"
      },
      "outputs": [],
      "source": [
        "# @title Stitching Parameters\n",
        "OUTPUT_WITHOUT_AUDIO = 'video_transition_demo.mp4'\n",
        "OUTPUT_WITH_AUDIO = 'video_transition_demo_audio.mp4'\n",
        "\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "TRANSITION = \"SWIPE\" # @param [\"CROSS_FADE\", \"FADE_IN\", \"SWIPE\", \"SLIDE_IN\"]\n",
        "TRANSITON_DURATION = 0.5 # @param {type:\"number\"}\n",
        "TRANSITION_SIDE = \"left\" # @param [\"left\", \"right\", \"top\", \"bottom\"]\n",
        "\n",
        "TRANSITION_TEST = models.VideoTransition(\n",
        "    name=TRANSITION,\n",
        "    padding=TRANSITON_DURATION,\n",
        "    side=TRANSITION_SIDE\n",
        ")\n",
        "OUTPUT_LENGHT = 23 # @param {type:\"slider\", min:10, max:30, step:1}\n",
        "TRIM_FROM = \"end\" # @param [\"start\", \"end\"]\n",
        "TRIM_ENABLED = True # @param {type:\"boolean\"}\n",
        "\n",
        "UPSCALE_FACTOR = 2 #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIuFgimcdSpX"
      },
      "outputs": [],
      "source": [
        "#@title Define app settings\n",
        "\n",
        "APP_SETTINGS = config.AppSettings(\n",
        "  gcp_project_id=GCP_PROJECT_ID,\n",
        "  gcp_bucket_name=GCP_BUCKET_NAME,\n",
        "  gcs_folder_name=FOLDER_NAME,\n",
        "  gcp_region=LOCATION,\n",
        "\n",
        "  veo_model_name=video_model,\n",
        "  veo_duration_seconds=DURATION,\n",
        "  veo_sample_count=SAMPLE_COUNT,\n",
        "  veo_negative_prompt=NEGATIVE_PROMPT,\n",
        "  veo_prompt_enhance=PROMPT_ENHANCE,\n",
        "  veo_person_generation=PERSON_GENERATION,\n",
        "\n",
        "  gemini_model_name=gemini_model,\n",
        "  prompt_type=PROMPT_TYPE,\n",
        "  custom_video_prompt=CUSTOM_VIDEO_PROMPT,\n",
        "  gemini_base_prompt=GENERATE_VIDEO_PROMPT,\n",
        "\n",
        "  video_orientation=VIDEO_ORIENTATION,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_wifFZ-HbB6"
      },
      "source": [
        "## Backend Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtEzvgCPI8MH"
      },
      "outputs": [],
      "source": [
        "# @title Get User Video Selection Functions\n",
        "def get_user_choice_with_videos(videos: list[dict], on_selection_callback) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Allows the user to choose multiple options from a list with video thumbnails.\n",
        "\n",
        "    Args:\n",
        "        videos: A list of dictionaries, where each dictionary represents a video\n",
        "                and contains keys \"local_file\" for the local video path,\n",
        "                \"product_title\" for the video title, and \"promo_text\"\n",
        "                for any promotional text.\n",
        "        on_selection_callback: A function to call with the selected videos\n",
        "                once the user submits.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries, each containing gcs_url, and title\n",
        "        of the selected videos.\n",
        "    \"\"\"\n",
        "    # Create checkboxes and video widgets\n",
        "    checkboxes = [widgets.Checkbox(\n",
        "        value=False,\n",
        "        description=f\"{video['product_title']}\") for video in videos]\n",
        "\n",
        "    # Create video elements using local file paths\n",
        "    video_elements = []\n",
        "    for video in videos:\n",
        "        local_video_path = video['local_file']\n",
        "\n",
        "        # Encode the video file as base64\n",
        "        with open(local_video_path, \"rb\") as f:\n",
        "            video_data = f.read()\n",
        "        encoded_video = base64.b64encode(video_data).decode()\n",
        "\n",
        "        # Create video element using base64 encoded data\n",
        "        video_element = f\"\"\"\n",
        "        <video width=\"320\" height=\"240\" controls>\n",
        "            <source src=\"data:video/mp4;base64,{encoded_video}\" type=\"video/mp4\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        \"\"\"\n",
        "        video_elements.append(widgets.HTML(value=video_element))\n",
        "\n",
        "    # Create a text field for promo_title\n",
        "    promo_title_inputs = [widgets.Text(\n",
        "        value=\"\",\n",
        "        placeholder=\"Enter promo text:\",\n",
        "        description=f\"{video['promo_text']}\") for video in videos]\n",
        "\n",
        "    # Create a container to arrange checkboxes and videos\n",
        "    items = []\n",
        "    for checkbox, video_widget, promot_title_input in zip(\n",
        "        checkboxes, video_elements, promo_title_inputs\n",
        "    ):\n",
        "      items.extend([\n",
        "          video_widget,\n",
        "          checkbox,\n",
        "          widgets.HTML(value=\"<br>\"),\n",
        "          promot_title_input\n",
        "      ])\n",
        "    container = widgets.VBox(items)\n",
        "\n",
        "    display(container)\n",
        "\n",
        "    def on_button_clicked(button):\n",
        "        \"\"\"This function processes the selected videos and promo texts, and\n",
        "        provides feedback to the user.\n",
        "        \"\"\"\n",
        "        try:\n",
        "          selected_videos = []\n",
        "          clear_output(wait=True)  # Clear previous output\n",
        "          for i, checkbox in enumerate(checkboxes):\n",
        "            if checkbox.value:\n",
        "                video = videos[i]\n",
        "                selected_videos.append(video)\n",
        "                video['promo_text'] = promo_title_inputs[i].value\n",
        "          print(selected_videos)\n",
        "          on_selection_callback(selected_videos) # Call the provided callback\n",
        "          return selected_videos\n",
        "        except Exception as e:\n",
        "          print(f'Error on_button_click {e} in get_user_choice_with_videos()')\n",
        "\n",
        "    submit_button = widgets.Button(description=\"Submit\")\n",
        "    submit_button.on_click(on_button_clicked)\n",
        "    display(submit_button)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_GYY69Iu3uG"
      },
      "outputs": [],
      "source": [
        "#@title Video Stitching Functions\n",
        "def select_videos_for_concatenation(\n",
        "    local_video_paths: list[str],\n",
        "    transition: models.VideoTransition,\n",
        "    output_length: int,\n",
        "    trim_location: str,\n",
        "    audio_inputs: list[models.AudioInput],\n",
        "    gcs_uri: str,\n",
        "    output_without_audio: str,\n",
        "    output_with_audio: str\n",
        "  ) -> list:\n",
        "  \"\"\"Selects videos for concatenation and returns them with an audio clip.\n",
        "\n",
        "  Args:\n",
        "    local_video_paths: A list of local paths to the video files.\n",
        "    transition: A VideoTransition object with the transition type and duration.\n",
        "    output_length: The desired length of the output video in seconds.\n",
        "    trim_location: Where to trim the videos (\"start\" or \"end\").\n",
        "    audio_inputs: A list of AudioInput objects for audio overlay.\n",
        "    gcs_uri: The GCS URI for uploading the final video.\n",
        "\n",
        "  Returns:\n",
        "    A list of selected videos\n",
        "    \"\"\"\n",
        "  try:\n",
        "    checkboxes = [\n",
        "        widgets.Checkbox(value=False, description=path)\n",
        "        for path in local_video_paths\n",
        "    ]\n",
        "    container = widgets.VBox(checkboxes)\n",
        "    display(container)\n",
        "\n",
        "    submit_button = widgets.Button(description=\"Submit\")\n",
        "    display(submit_button)\n",
        "\n",
        "    selected_videos = []\n",
        "\n",
        "    def on_button_clicked(button):\n",
        "      nonlocal selected_videos\n",
        "      clear_output(wait=True)\n",
        "      for path, checkbox in zip(local_video_paths, checkboxes):\n",
        "        if checkbox.value:\n",
        "          selected_videos.append(path)\n",
        "      final_video = video.concatenate_video_clips(\n",
        "          selected_videos,\n",
        "          transition,\n",
        "          output_length,\n",
        "          trim_location,\n",
        "          resized_image_width = RESIZED_IMAGE_WIDTH,\n",
        "          resized_image_height = RESIZED_IMAGE_HEIGHT,\n",
        "          tmp_string = TMP_STRING\n",
        "      )\n",
        "\n",
        "      gcs_uri_video = f'{gcs_uri}{output_without_audio}'\n",
        "      gcs_uri_audio = f'{gcs_uri}{output_with_audio}'\n",
        "\n",
        "      video.add_audio_clips_to_video(final_video, audio_inputs, gcs_uri_audio)\n",
        "      gcs.upload_file_to_gcs(final_video, gcs_uri_video)\n",
        "\n",
        "    submit_button.on_click(on_button_clicked)\n",
        "\n",
        "    return selected_videos\n",
        "  except Exception as e:\n",
        "    print(f'Error select_videos_for_concatenation {e}')\n",
        "\n",
        "\n",
        "def stitch_videos_with_transitions(\n",
        "    veo_clips_uri: str,\n",
        "    stiching_output_uri: str,\n",
        "    output_with_audio: str,\n",
        "    output_without_audio: str,\n",
        "    transition: str,\n",
        "    transition_duration: float,\n",
        "    transition_side: str,\n",
        "    desired_length: int,\n",
        "    trim_from: str,\n",
        "    settings: config.AppSettings\n",
        ") -> None:\n",
        "    \"\"\"Stitches videos with transitions, overlays audio, and uploads to gcs.\n",
        "\n",
        "    Args:\n",
        "        veo_clips_uri: The GCS URI of the folder containing Veo overlay videos.\n",
        "        stiching_output_uri: The GCS URI for the stitched video to be uploaded.\n",
        "        output_with_audio: The filename for the stitched video with audio.\n",
        "        output_without_audio: The filename for the stitched video without audio.\n",
        "        transition: The name of the transition to use (e.g., \"CROSS_FADE\"...).\n",
        "        transition_duration: The duration of the transition in seconds.\n",
        "        transition_side: The side of the transition (e.g., \"left\", \"right\").\n",
        "        desired_length: The desired length of the output video in seconds.\n",
        "        trim_from: Where to trim the video (\"start\" or \"end\").\n",
        "        settings: An instance of AppSettings containing configuration\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    # 1. Retrieve videos and audio from GCS\n",
        "    intro_outro_videos = gcs.retrieve_all_files_from_gcs_folder(\n",
        "        settings.intro_outro_videos_uri\n",
        "    )\n",
        "    input_veo_clips = gcs.retrieve_all_files_from_gcs_folder(veo_clips_uri)\n",
        "    input_videos = video.merge_arrays(intro_outro_videos, input_veo_clips)\n",
        "    input_audio = gcs.retrieve_all_files_from_gcs_folder(settings.audio_uri)\n",
        "\n",
        "    video_transition = models.VideoTransition(\n",
        "        name=transition,\n",
        "        padding=transition_duration,\n",
        "        side=transition_side\n",
        "    )\n",
        "\n",
        "    # 2. Download videos and audio locally\n",
        "    local_video_paths = gcs.download_files(input_videos)\n",
        "    local_audio_paths = [\n",
        "        models.AudioInput(path=path) for path in gcs.download_files(input_audio)\n",
        "    ]\n",
        "\n",
        "    # 3. Concatenate videos, apply transitions, and overlay audio\n",
        "    selected_videos = select_videos_for_concatenation(\n",
        "        local_video_paths,\n",
        "        video_transition,\n",
        "        desired_length,\n",
        "        trim_from,\n",
        "        local_audio_paths,\n",
        "        stiching_output_uri,\n",
        "        output_without_audio,\n",
        "        output_with_audio\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEBjgdAQq35g"
      },
      "outputs": [],
      "source": [
        "#@title Main functions\n",
        "\n",
        "def select_videos(output_video_files:list[dict])->list[dict]:    \n",
        "    # This list will be populated by a callback\n",
        "    final_selected_videos = []\n",
        "\n",
        "    def handle_user_selection(selected_items: list[dict]):\n",
        "        \"\"\"This function will be called when the user clicks submit.\"\"\"\n",
        "        print(\"User selection received in generate_and_select_videos context.\")\n",
        "        final_selected_videos.extend(selected_items) # Populate the list\n",
        "        print(\"Final selected videos:\", final_selected_videos)\n",
        "\n",
        "    print(\"Please select your videos from the UI below:\")\n",
        "    get_user_choice_with_videos(output_video_files, handle_user_selection)\n",
        "    return final_selected_videos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp3jvuXeLw2u"
      },
      "source": [
        "# Execute Main Functions\n",
        "\n",
        "## Part 1: Image resize, background recolor, veos generation and user selection\n",
        "\n",
        "The cell from part1 execute in approximately **1 minute**. However it waits on user input and is not finished until the user makes the selection and clicks the 'Submit' button.\n",
        "\n",
        "**Important**: If you run the next cell before you make the selection of the provided Veo generated videos and add the promo text, you will see errors. Please select the videos and promo texts before moving to the next one.\n",
        "\n",
        "## Part 2: Overlaying the Veos videos with image and text overlays and final videos stiching: intro, overlayed veos, outro and audio\n",
        "\n",
        "The cell from part2 executes in approximately **8 minutes**. However it waits on the user input to select which videos to stitch together: intro, overlayed veos and outro, and is not finished until the user makes the selection and clicks the 'Submit' button.\n",
        "\n",
        "**Important**: If you run the next cell before you make the selection of the provided video parts, you will see errors. Please select the video parts before moving to the next one.\n",
        "It will take in total between 15-20 minutes for this cell to finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFX0Q3Wvy0b4"
      },
      "outputs": [],
      "source": [
        "#@title Part 1\n",
        "\n",
        "output_video_files = video.generate_videos(\n",
        "    OUTPUT_URI_PATH,\n",
        "    RESIZED_IMAGE_WIDTH,\n",
        "    RESIZED_IMAGE_HEIGHT,\n",
        "    ORIGINAL_BACKGROUND_COLOR,\n",
        "    BACKGROUND_COLOR,\n",
        "    APP_SETTINGS\n",
        ")\n",
        "\n",
        "selected_videos = select_videos(output_video_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot-Utq148whF"
      },
      "outputs": [],
      "source": [
        "#@title Part 2\n",
        "# Please wait until previous cell is complete before running this one\n",
        "video.process_videos_with_overlays_and_text(\n",
        "    selected_videos,\n",
        "    GCS_IMAGES_TEST,\n",
        "    TEXT_TEST,\n",
        "    IMAGE_OVERLAYS_PATH,\n",
        "    FINAL_OVERLAYS_PATH\n",
        ")\n",
        "\n",
        "stitch_videos_with_transitions(\n",
        "    VEO_CLIPS_URI,\n",
        "    STITCHING_OUTPUT_URI,\n",
        "    OUTPUT_WITH_AUDIO,\n",
        "    OUTPUT_WITHOUT_AUDIO,\n",
        "    TRANSITION,\n",
        "    TRANSITON_DURATION,\n",
        "    TRANSITION_SIDE,\n",
        "    OUTPUT_LENGHT,\n",
        "    TRIM_FROM,\n",
        "    APP_SETTINGS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIKh039e-Kr3"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Upscale the local video to higher resolution\n",
        "def upscale_video(\n",
        "    input_video_path,\n",
        "    output_video_path,\n",
        "    target_width,\n",
        "    target_height):\n",
        "  \"\"\"Upscales a video to a higher resolution using ffmpeg.\n",
        "\n",
        "  Args:\n",
        "      input_video_path: The path to the input video file.\n",
        "      output_video_path: The path to the output video file.\n",
        "      target_width: The desired width of the upscaled video.\n",
        "      target_height: The desired height of the upscaled video.\n",
        "  \"\"\"\n",
        "  !ffmpeg -i {input_video_path} -vf scale={target_width}:{target_height} -c:a copy {output_video_path}\n",
        "\n",
        "# Example usage:\n",
        "output_video_path = f'{TMP_STRING}/upscaled_video.mp4'\n",
        "target_width = UPSCALE_FACTOR * RESIZED_IMAGE_WIDTH\n",
        "target_height = UPSCALE_FACTOR * RESIZED_IMAGE_WIDTH\n",
        "\n",
        "video_audio_filename = gcs.download_file_locally(\n",
        "    f'{STITCHING_OUTPUT_URI}{OUTPUT_WITH_AUDIO}')\n",
        "upscale_video(\n",
        "    video_audio_filename,\n",
        "    output_video_path,\n",
        "    target_width,\n",
        "    target_height\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XblYMBVdJfJ"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Clean up local files\n",
        "def cleanup_tmp_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Removes all files and subdirectories within the specified folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder to clean up.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if os.path.exists(file_path):\n",
        "          os.remove(file_path)\n",
        "\n",
        "\n",
        "# Call the function with the TMP_STRING folder path\n",
        "cleanup_tmp_folder(TMP_STRING)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
